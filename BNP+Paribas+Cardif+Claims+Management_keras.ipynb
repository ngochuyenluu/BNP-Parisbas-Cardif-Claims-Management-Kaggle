{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = '/Users/ngochuyenluu/Downloads/BNP/train.csv'\n",
    "test_path = '/Users/ngochuyenluu/Downloads/BNP/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "  \"\"\"\n",
    "  Convert class labels from scalars to one-hot vectors.\n",
    "  http://stackoverflow.com/questions/33681517/tensorflow-one-hot-encoder\n",
    "  \"\"\"\n",
    "  labels_dense = np.array(labels_dense)\n",
    "  num_labels = labels_dense.shape[0]\n",
    "  index_offset = np.arange(num_labels) * num_classes\n",
    "  labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "  return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(path, is_test_set=False):\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    if is_test_set:\n",
    "        df = df.interpolate()\n",
    "\n",
    "    # Ignoring categorical input\n",
    "    df = df.drop('v3', axis=1)\n",
    "    df = df.drop('v22', axis=1)\n",
    "    df = df.drop('v24', axis=1)\n",
    "    df = df.drop('v30', axis=1)\n",
    "    df = df.drop('v31', axis=1)\n",
    "    df = df.drop('v47', axis=1)\n",
    "    df = df.drop('v52', axis=1)\n",
    "    df = df.drop('v56', axis=1)\n",
    "    df = df.drop('v66', axis=1)\n",
    "    df = df.drop('v71', axis=1)\n",
    "    df = df.drop('v74', axis=1)\n",
    "    df = df.drop('v75', axis=1)\n",
    "    df = df.drop('v79', axis=1)\n",
    "    df = df.drop('v91', axis=1)\n",
    "    df = df.drop('v107', axis=1)\n",
    "    df = df.drop('v110', axis=1)\n",
    "    df = df.drop('v112', axis=1)\n",
    "    df = df.drop('v113', axis=1)\n",
    "    df = df.drop('v125', axis=1)\n",
    "    \n",
    "    if not is_test_set:\n",
    "        # Ignore datapoints with missing values\n",
    "        df = df.dropna()\n",
    "        \n",
    "        labels = df['target'].values.tolist()\n",
    "        labels = dense_to_one_hot(labels, 2)\n",
    "        df = df.drop('ID', axis=1)\n",
    "        df = df.drop('target', axis=1)\n",
    "        \n",
    "        # Normalize the data\n",
    "        df_norm = (df - df.mean()) / (df.max() - df.min())\n",
    "        data = df_norm.values.tolist()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels,\n",
    "                                                test_size=0.15, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    else:\n",
    "        ids = df['ID'].values.tolist()\n",
    "        df = df.drop('ID', axis=1)\n",
    "        df_norm = (df - df.mean()) / (df.max() - df.min())\n",
    "        data = df_norm.values.tolist()\n",
    "        return data, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = process_data(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, advanced_activations\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53176 samples, validate on 9385 samples\n",
      "Epoch 1/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5284 - mean_squared_error: 0.1756 - acc: 0.7526 - val_loss: 0.5226 - val_mean_squared_error: 0.1731 - val_acc: 0.7535\n",
      "Epoch 2/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5157 - mean_squared_error: 0.1707 - acc: 0.7544 - val_loss: 0.5180 - val_mean_squared_error: 0.1716 - val_acc: 0.7530\n",
      "Epoch 3/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5138 - mean_squared_error: 0.1699 - acc: 0.7547 - val_loss: 0.5207 - val_mean_squared_error: 0.1730 - val_acc: 0.7492\n",
      "Epoch 4/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5109 - mean_squared_error: 0.1689 - acc: 0.7571 - val_loss: 0.5166 - val_mean_squared_error: 0.1713 - val_acc: 0.7560\n",
      "Epoch 5/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5099 - mean_squared_error: 0.1686 - acc: 0.7570 - val_loss: 0.5152 - val_mean_squared_error: 0.1707 - val_acc: 0.7554\n",
      "Epoch 6/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5079 - mean_squared_error: 0.1679 - acc: 0.7581 - val_loss: 0.5200 - val_mean_squared_error: 0.1728 - val_acc: 0.7462\n",
      "Epoch 7/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5065 - mean_squared_error: 0.1673 - acc: 0.7586 - val_loss: 0.5172 - val_mean_squared_error: 0.1719 - val_acc: 0.7521\n",
      "Epoch 8/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5054 - mean_squared_error: 0.1670 - acc: 0.7593 - val_loss: 0.5166 - val_mean_squared_error: 0.1718 - val_acc: 0.7507\n",
      "Epoch 9/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5040 - mean_squared_error: 0.1665 - acc: 0.7610 - val_loss: 0.5162 - val_mean_squared_error: 0.1714 - val_acc: 0.7523\n",
      "Epoch 10/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5033 - mean_squared_error: 0.1662 - acc: 0.7609 - val_loss: 0.5146 - val_mean_squared_error: 0.1704 - val_acc: 0.7549\n",
      "Epoch 11/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5014 - mean_squared_error: 0.1655 - acc: 0.7629 - val_loss: 0.5185 - val_mean_squared_error: 0.1713 - val_acc: 0.7551\n",
      "Epoch 12/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.5012 - mean_squared_error: 0.1653 - acc: 0.7628 - val_loss: 0.5143 - val_mean_squared_error: 0.1705 - val_acc: 0.7574\n",
      "Epoch 13/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4998 - mean_squared_error: 0.1649 - acc: 0.7642 - val_loss: 0.5143 - val_mean_squared_error: 0.1708 - val_acc: 0.7513\n",
      "Epoch 14/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4986 - mean_squared_error: 0.1645 - acc: 0.7632 - val_loss: 0.5141 - val_mean_squared_error: 0.1705 - val_acc: 0.7536\n",
      "Epoch 15/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4979 - mean_squared_error: 0.1641 - acc: 0.7642 - val_loss: 0.5149 - val_mean_squared_error: 0.1710 - val_acc: 0.7507\n",
      "Epoch 16/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4965 - mean_squared_error: 0.1636 - acc: 0.7651 - val_loss: 0.5138 - val_mean_squared_error: 0.1704 - val_acc: 0.7554\n",
      "Epoch 17/100\n",
      "53176/53176 [==============================] - 3s - loss: 0.4949 - mean_squared_error: 0.1630 - acc: 0.7665 - val_loss: 0.5154 - val_mean_squared_error: 0.1710 - val_acc: 0.7536\n",
      "Epoch 18/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4943 - mean_squared_error: 0.1627 - acc: 0.7665 - val_loss: 0.5171 - val_mean_squared_error: 0.1718 - val_acc: 0.7522\n",
      "Epoch 19/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4933 - mean_squared_error: 0.1624 - acc: 0.7677 - val_loss: 0.5131 - val_mean_squared_error: 0.1703 - val_acc: 0.7563\n",
      "Epoch 20/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4922 - mean_squared_error: 0.1620 - acc: 0.7667 - val_loss: 0.5187 - val_mean_squared_error: 0.1726 - val_acc: 0.7470\n",
      "Epoch 21/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4915 - mean_squared_error: 0.1618 - acc: 0.7677 - val_loss: 0.5195 - val_mean_squared_error: 0.1732 - val_acc: 0.7449\n",
      "Epoch 22/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4901 - mean_squared_error: 0.1612 - acc: 0.7691 - val_loss: 0.5168 - val_mean_squared_error: 0.1714 - val_acc: 0.7560\n",
      "Epoch 23/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4889 - mean_squared_error: 0.1607 - acc: 0.7700 - val_loss: 0.5188 - val_mean_squared_error: 0.1723 - val_acc: 0.7532\n",
      "Epoch 24/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4881 - mean_squared_error: 0.1605 - acc: 0.7688 - val_loss: 0.5172 - val_mean_squared_error: 0.1717 - val_acc: 0.7503\n",
      "Epoch 25/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4865 - mean_squared_error: 0.1599 - acc: 0.7700 - val_loss: 0.5203 - val_mean_squared_error: 0.1725 - val_acc: 0.7549\n",
      "Epoch 26/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4858 - mean_squared_error: 0.1596 - acc: 0.7719 - val_loss: 0.5243 - val_mean_squared_error: 0.1738 - val_acc: 0.7522\n",
      "Epoch 27/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4855 - mean_squared_error: 0.1595 - acc: 0.7714 - val_loss: 0.5206 - val_mean_squared_error: 0.1733 - val_acc: 0.7502\n",
      "Epoch 28/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4844 - mean_squared_error: 0.1591 - acc: 0.7718 - val_loss: 0.5191 - val_mean_squared_error: 0.1724 - val_acc: 0.7507\n",
      "Epoch 29/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4838 - mean_squared_error: 0.1589 - acc: 0.7710 - val_loss: 0.5199 - val_mean_squared_error: 0.1730 - val_acc: 0.7507\n",
      "Epoch 30/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4823 - mean_squared_error: 0.1583 - acc: 0.7723 - val_loss: 0.5249 - val_mean_squared_error: 0.1751 - val_acc: 0.7416\n",
      "Epoch 31/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4817 - mean_squared_error: 0.1580 - acc: 0.7736 - val_loss: 0.5251 - val_mean_squared_error: 0.1750 - val_acc: 0.7458\n",
      "Epoch 32/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4807 - mean_squared_error: 0.1577 - acc: 0.7735 - val_loss: 0.5234 - val_mean_squared_error: 0.1741 - val_acc: 0.7487\n",
      "Epoch 33/100\n",
      "53176/53176 [==============================] - 3s - loss: 0.4801 - mean_squared_error: 0.1575 - acc: 0.7740 - val_loss: 0.5245 - val_mean_squared_error: 0.1749 - val_acc: 0.7447\n",
      "Epoch 34/100\n",
      "53176/53176 [==============================] - 3s - loss: 0.4792 - mean_squared_error: 0.1571 - acc: 0.7748 - val_loss: 0.5263 - val_mean_squared_error: 0.1744 - val_acc: 0.7512\n",
      "Epoch 35/100\n",
      "53176/53176 [==============================] - 3s - loss: 0.4779 - mean_squared_error: 0.1566 - acc: 0.7756 - val_loss: 0.5302 - val_mean_squared_error: 0.1768 - val_acc: 0.7400\n",
      "Epoch 36/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4778 - mean_squared_error: 0.1567 - acc: 0.7749 - val_loss: 0.5298 - val_mean_squared_error: 0.1758 - val_acc: 0.7476\n",
      "Epoch 37/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4763 - mean_squared_error: 0.1560 - acc: 0.7768 - val_loss: 0.5284 - val_mean_squared_error: 0.1762 - val_acc: 0.7431\n",
      "Epoch 38/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4765 - mean_squared_error: 0.1561 - acc: 0.7764 - val_loss: 0.5308 - val_mean_squared_error: 0.1769 - val_acc: 0.7413\n",
      "Epoch 39/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4753 - mean_squared_error: 0.1557 - acc: 0.7768 - val_loss: 0.5314 - val_mean_squared_error: 0.1767 - val_acc: 0.7470\n",
      "Epoch 40/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4747 - mean_squared_error: 0.1554 - acc: 0.7778 - val_loss: 0.5296 - val_mean_squared_error: 0.1765 - val_acc: 0.7418\n",
      "Epoch 41/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4733 - mean_squared_error: 0.1548 - acc: 0.7779 - val_loss: 0.5338 - val_mean_squared_error: 0.1779 - val_acc: 0.7432\n",
      "Epoch 42/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4727 - mean_squared_error: 0.1546 - acc: 0.7791 - val_loss: 0.5338 - val_mean_squared_error: 0.1783 - val_acc: 0.7398\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53176/53176 [==============================] - 2s - loss: 0.4718 - mean_squared_error: 0.1543 - acc: 0.7788 - val_loss: 0.5350 - val_mean_squared_error: 0.1783 - val_acc: 0.7414\n",
      "Epoch 44/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4714 - mean_squared_error: 0.1543 - acc: 0.7777 - val_loss: 0.5327 - val_mean_squared_error: 0.1769 - val_acc: 0.7434\n",
      "Epoch 45/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4704 - mean_squared_error: 0.1538 - acc: 0.7794 - val_loss: 0.5341 - val_mean_squared_error: 0.1780 - val_acc: 0.7426\n",
      "Epoch 46/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4695 - mean_squared_error: 0.1536 - acc: 0.7802 - val_loss: 0.5352 - val_mean_squared_error: 0.1776 - val_acc: 0.7453\n",
      "Epoch 47/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4689 - mean_squared_error: 0.1533 - acc: 0.7801 - val_loss: 0.5365 - val_mean_squared_error: 0.1783 - val_acc: 0.7429\n",
      "Epoch 48/100\n",
      "53176/53176 [==============================] - 3s - loss: 0.4685 - mean_squared_error: 0.1532 - acc: 0.7806 - val_loss: 0.5403 - val_mean_squared_error: 0.1802 - val_acc: 0.7377\n",
      "Epoch 49/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4683 - mean_squared_error: 0.1530 - acc: 0.7804 - val_loss: 0.5340 - val_mean_squared_error: 0.1772 - val_acc: 0.7456\n",
      "Epoch 50/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4669 - mean_squared_error: 0.1525 - acc: 0.7811 - val_loss: 0.5373 - val_mean_squared_error: 0.1792 - val_acc: 0.7373\n",
      "Epoch 51/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4660 - mean_squared_error: 0.1522 - acc: 0.7822 - val_loss: 0.5402 - val_mean_squared_error: 0.1796 - val_acc: 0.7360\n",
      "Epoch 52/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4657 - mean_squared_error: 0.1522 - acc: 0.7822 - val_loss: 0.5396 - val_mean_squared_error: 0.1799 - val_acc: 0.7365\n",
      "Epoch 53/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4645 - mean_squared_error: 0.1516 - acc: 0.7829 - val_loss: 0.5368 - val_mean_squared_error: 0.1777 - val_acc: 0.7432\n",
      "Epoch 54/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4641 - mean_squared_error: 0.1516 - acc: 0.7824 - val_loss: 0.5399 - val_mean_squared_error: 0.1796 - val_acc: 0.7393\n",
      "Epoch 55/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4633 - mean_squared_error: 0.1511 - acc: 0.7839 - val_loss: 0.5450 - val_mean_squared_error: 0.1812 - val_acc: 0.7368\n",
      "Epoch 56/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4628 - mean_squared_error: 0.1510 - acc: 0.7833 - val_loss: 0.5425 - val_mean_squared_error: 0.1801 - val_acc: 0.7387\n",
      "Epoch 57/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4619 - mean_squared_error: 0.1507 - acc: 0.7835 - val_loss: 0.5425 - val_mean_squared_error: 0.1802 - val_acc: 0.7394\n",
      "Epoch 58/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4608 - mean_squared_error: 0.1501 - acc: 0.7848 - val_loss: 0.5413 - val_mean_squared_error: 0.1794 - val_acc: 0.7391\n",
      "Epoch 59/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4603 - mean_squared_error: 0.1501 - acc: 0.7852 - val_loss: 0.5517 - val_mean_squared_error: 0.1833 - val_acc: 0.7308\n",
      "Epoch 60/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4598 - mean_squared_error: 0.1500 - acc: 0.7854 - val_loss: 0.5466 - val_mean_squared_error: 0.1796 - val_acc: 0.7448\n",
      "Epoch 61/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4592 - mean_squared_error: 0.1497 - acc: 0.7852 - val_loss: 0.5501 - val_mean_squared_error: 0.1812 - val_acc: 0.7420\n",
      "Epoch 62/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4587 - mean_squared_error: 0.1495 - acc: 0.7860 - val_loss: 0.5473 - val_mean_squared_error: 0.1815 - val_acc: 0.7380\n",
      "Epoch 63/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4580 - mean_squared_error: 0.1492 - acc: 0.7863 - val_loss: 0.5487 - val_mean_squared_error: 0.1823 - val_acc: 0.7340\n",
      "Epoch 64/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4571 - mean_squared_error: 0.1489 - acc: 0.7862 - val_loss: 0.5525 - val_mean_squared_error: 0.1818 - val_acc: 0.7370\n",
      "Epoch 65/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4561 - mean_squared_error: 0.1485 - acc: 0.7870 - val_loss: 0.5483 - val_mean_squared_error: 0.1811 - val_acc: 0.7404\n",
      "Epoch 66/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4552 - mean_squared_error: 0.1482 - acc: 0.7876 - val_loss: 0.5506 - val_mean_squared_error: 0.1812 - val_acc: 0.7406\n",
      "Epoch 67/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4550 - mean_squared_error: 0.1481 - acc: 0.7873 - val_loss: 0.5518 - val_mean_squared_error: 0.1833 - val_acc: 0.7336\n",
      "Epoch 68/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4539 - mean_squared_error: 0.1478 - acc: 0.7880 - val_loss: 0.5516 - val_mean_squared_error: 0.1816 - val_acc: 0.7422\n",
      "Epoch 69/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4539 - mean_squared_error: 0.1476 - acc: 0.7891 - val_loss: 0.5511 - val_mean_squared_error: 0.1828 - val_acc: 0.7366\n",
      "Epoch 70/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4531 - mean_squared_error: 0.1474 - acc: 0.7878 - val_loss: 0.5576 - val_mean_squared_error: 0.1825 - val_acc: 0.7427\n",
      "Epoch 71/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4531 - mean_squared_error: 0.1475 - acc: 0.7882 - val_loss: 0.5549 - val_mean_squared_error: 0.1830 - val_acc: 0.7411\n",
      "Epoch 72/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4523 - mean_squared_error: 0.1472 - acc: 0.7892 - val_loss: 0.5617 - val_mean_squared_error: 0.1848 - val_acc: 0.7339\n",
      "Epoch 73/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4513 - mean_squared_error: 0.1467 - acc: 0.7901 - val_loss: 0.5589 - val_mean_squared_error: 0.1834 - val_acc: 0.7388\n",
      "Epoch 74/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4519 - mean_squared_error: 0.1469 - acc: 0.7905 - val_loss: 0.5543 - val_mean_squared_error: 0.1821 - val_acc: 0.7429\n",
      "Epoch 75/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4513 - mean_squared_error: 0.1468 - acc: 0.7896 - val_loss: 0.5553 - val_mean_squared_error: 0.1832 - val_acc: 0.7371\n",
      "Epoch 76/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4504 - mean_squared_error: 0.1464 - acc: 0.7894 - val_loss: 0.5577 - val_mean_squared_error: 0.1855 - val_acc: 0.7283\n",
      "Epoch 77/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4498 - mean_squared_error: 0.1462 - acc: 0.7903 - val_loss: 0.5580 - val_mean_squared_error: 0.1836 - val_acc: 0.7362\n",
      "Epoch 78/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4489 - mean_squared_error: 0.1458 - acc: 0.7921 - val_loss: 0.5554 - val_mean_squared_error: 0.1824 - val_acc: 0.7405\n",
      "Epoch 79/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4495 - mean_squared_error: 0.1461 - acc: 0.7908 - val_loss: 0.5605 - val_mean_squared_error: 0.1841 - val_acc: 0.7375\n",
      "Epoch 80/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4484 - mean_squared_error: 0.1457 - acc: 0.7916 - val_loss: 0.5533 - val_mean_squared_error: 0.1833 - val_acc: 0.7340\n",
      "Epoch 81/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4479 - mean_squared_error: 0.1456 - acc: 0.7926 - val_loss: 0.5573 - val_mean_squared_error: 0.1839 - val_acc: 0.7351\n",
      "Epoch 82/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4466 - mean_squared_error: 0.1450 - acc: 0.7930 - val_loss: 0.5605 - val_mean_squared_error: 0.1833 - val_acc: 0.7436\n",
      "Epoch 83/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4467 - mean_squared_error: 0.1452 - acc: 0.7903 - val_loss: 0.5600 - val_mean_squared_error: 0.1833 - val_acc: 0.7385\n",
      "Epoch 84/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4461 - mean_squared_error: 0.1448 - acc: 0.7934 - val_loss: 0.5665 - val_mean_squared_error: 0.1859 - val_acc: 0.7364\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53176/53176 [==============================] - 2s - loss: 0.4466 - mean_squared_error: 0.1450 - acc: 0.7929 - val_loss: 0.5613 - val_mean_squared_error: 0.1844 - val_acc: 0.7368\n",
      "Epoch 86/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4451 - mean_squared_error: 0.1444 - acc: 0.7940 - val_loss: 0.5598 - val_mean_squared_error: 0.1843 - val_acc: 0.7349\n",
      "Epoch 87/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4444 - mean_squared_error: 0.1443 - acc: 0.7948 - val_loss: 0.5613 - val_mean_squared_error: 0.1858 - val_acc: 0.7316\n",
      "Epoch 88/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4442 - mean_squared_error: 0.1441 - acc: 0.7935 - val_loss: 0.5663 - val_mean_squared_error: 0.1847 - val_acc: 0.7382\n",
      "Epoch 89/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4435 - mean_squared_error: 0.1439 - acc: 0.7933 - val_loss: 0.5739 - val_mean_squared_error: 0.1873 - val_acc: 0.7319\n",
      "Epoch 90/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4436 - mean_squared_error: 0.1440 - acc: 0.7941 - val_loss: 0.5654 - val_mean_squared_error: 0.1845 - val_acc: 0.7382\n",
      "Epoch 91/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4424 - mean_squared_error: 0.1436 - acc: 0.7941 - val_loss: 0.5652 - val_mean_squared_error: 0.1851 - val_acc: 0.7378\n",
      "Epoch 92/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4421 - mean_squared_error: 0.1434 - acc: 0.7955 - val_loss: 0.5718 - val_mean_squared_error: 0.1854 - val_acc: 0.7386\n",
      "Epoch 93/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4417 - mean_squared_error: 0.1433 - acc: 0.7955 - val_loss: 0.5717 - val_mean_squared_error: 0.1869 - val_acc: 0.7343\n",
      "Epoch 94/100\n",
      "53176/53176 [==============================] - 3s - loss: 0.4412 - mean_squared_error: 0.1431 - acc: 0.7956 - val_loss: 0.5693 - val_mean_squared_error: 0.1852 - val_acc: 0.7397\n",
      "Epoch 95/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4405 - mean_squared_error: 0.1428 - acc: 0.7953 - val_loss: 0.5651 - val_mean_squared_error: 0.1845 - val_acc: 0.7393\n",
      "Epoch 96/100\n",
      "53176/53176 [==============================] - 3s - loss: 0.4406 - mean_squared_error: 0.1429 - acc: 0.7949 - val_loss: 0.5699 - val_mean_squared_error: 0.1875 - val_acc: 0.7299\n",
      "Epoch 97/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4398 - mean_squared_error: 0.1426 - acc: 0.7973 - val_loss: 0.5759 - val_mean_squared_error: 0.1892 - val_acc: 0.7235\n",
      "Epoch 98/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4389 - mean_squared_error: 0.1423 - acc: 0.7965 - val_loss: 0.5765 - val_mean_squared_error: 0.1891 - val_acc: 0.7306\n",
      "Epoch 99/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4394 - mean_squared_error: 0.1425 - acc: 0.7966 - val_loss: 0.5693 - val_mean_squared_error: 0.1857 - val_acc: 0.7363\n",
      "Epoch 100/100\n",
      "53176/53176 [==============================] - 2s - loss: 0.4386 - mean_squared_error: 0.1420 - acc: 0.7977 - val_loss: 0.5682 - val_mean_squared_error: 0.1852 - val_acc: 0.7383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a14d07390>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1= Sequential()\n",
    "l1.add(Dense(150, input_dim=112,activation='tanh'))\n",
    "l1.add(Dense(50, activation='relu'))\n",
    "l1.add(Dense(20, activation='relu'))\n",
    "l1.add(Dense(2,activation='softmax'))\n",
    "optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "l1.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['mse','accuracy'])\n",
    "l1.fit(X_train, y_train, validation_data=(X_test,y_test),batch_size=100, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval, ids = process_data(test_path, True) \n",
    "\n",
    "outputs = l1.predict(X_eval)\n",
    "outputs = [x[1] for x in outputs[0]]\n",
    "\n",
    "submission = ['ID,PredictedProb']\n",
    "\n",
    "for prediction, id in zip(outputs, ids):\n",
    "    submission.append('{0},{1}'.format(id,prediction))\n",
    "\n",
    "submission = '\\n'.join(submission)\n",
    "\n",
    "with open('/Users/ngochuyenluu/Downloads/BNP/sample_submission.csv', 'w') as outfile:\n",
    "    outfile.write(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
