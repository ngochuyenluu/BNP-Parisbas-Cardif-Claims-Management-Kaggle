{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ngochuyenluu/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-2\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_path = '/Users/ngochuyenluu/Downloads/BNP/train.csv'\n",
    "test_path = '/Users/ngochuyenluu/Downloads/BNP/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "  \"\"\"\n",
    "  Convert class labels from scalars to one-hot vectors.\n",
    "  http://stackoverflow.com/questions/33681517/tensorflow-one-hot-encoder\n",
    "  \"\"\"\n",
    "  labels_dense = np.array(labels_dense)\n",
    "  num_labels = labels_dense.shape[0]\n",
    "  index_offset = np.arange(num_labels) * num_classes\n",
    "  labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "  return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(path, is_test_set=False):\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    if is_test_set:\n",
    "        df = df.interpolate()\n",
    "\n",
    "    # Ignoring categorical input\n",
    "    df = df.drop('v3', axis=1)\n",
    "    df = df.drop('v22', axis=1)\n",
    "    df = df.drop('v24', axis=1)\n",
    "    df = df.drop('v30', axis=1)\n",
    "    df = df.drop('v31', axis=1)\n",
    "    df = df.drop('v47', axis=1)\n",
    "    df = df.drop('v52', axis=1)\n",
    "    df = df.drop('v56', axis=1)\n",
    "    df = df.drop('v66', axis=1)\n",
    "    df = df.drop('v71', axis=1)\n",
    "    df = df.drop('v74', axis=1)\n",
    "    df = df.drop('v75', axis=1)\n",
    "    df = df.drop('v79', axis=1)\n",
    "    df = df.drop('v91', axis=1)\n",
    "    df = df.drop('v107', axis=1)\n",
    "    df = df.drop('v110', axis=1)\n",
    "    df = df.drop('v112', axis=1)\n",
    "    df = df.drop('v113', axis=1)\n",
    "    df = df.drop('v125', axis=1)\n",
    "    \n",
    "    if not is_test_set:\n",
    "        # Ignore datapoints with missing values\n",
    "        df = df.dropna()\n",
    "        \n",
    "        labels = df['target'].values.tolist()\n",
    "        labels = dense_to_one_hot(labels, 2)\n",
    "        df = df.drop('ID', axis=1)\n",
    "        df = df.drop('target', axis=1)\n",
    "        \n",
    "        # Normalize the data\n",
    "        df_norm = (df - df.mean()) / (df.max() - df.min())\n",
    "        data = df_norm.values.tolist()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels,\n",
    "                                                test_size=0.15, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    else:\n",
    "        ids = df['ID'].values.tolist()\n",
    "        df = df.drop('ID', axis=1)\n",
    "        df_norm = (df - df.mean()) / (df.max() - df.min())\n",
    "        data = df_norm.values.tolist()\n",
    "        return data, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input nodes for passing data into the graph\n",
    "x = tf.placeholder(tf.float32, [None, 112])\n",
    "y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# This is our model, a very simple, 1-layer MLP\n",
    "def multilayer_perceptron(_X, _weights, _biases):\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _weights[0]), _biases[0]))\n",
    "    return tf.matmul(layer_1, _weights[1]) + _biases[1]\n",
    "\n",
    "weights = [\n",
    "    tf.Variable(tf.random_normal([112, 50], seed=888)),\n",
    "    tf.Variable(tf.random_normal([50, 2], seed=888))\n",
    "]\n",
    "biases = [\n",
    "    tf.Variable(tf.random_normal([50], seed=888)),\n",
    "    tf.Variable(tf.random_normal([2], seed=888))\n",
    "]\n",
    "\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# This is only used during test time\n",
    "logits = tf.nn.softmax(pred)\n",
    "\n",
    "# Run cross entropy with an Adam optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : Valid loss\n",
      "2.797447443008423 : 2.2536232471466064\n",
      "0.6405801177024841 : 0.606364905834198\n",
      "0.5353475213050842 : 0.5632736682891846\n",
      "0.515095055103302 : 0.5467545986175537\n",
      "0.513008713722229 : 0.5367143750190735\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # We need to initialize the graph before we can use it\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = process_data(train_path)\n",
    "    data_len = len(X_train)\n",
    "    \n",
    "\n",
    "    print('\\nTrain loss : Valid loss')\n",
    "\n",
    "    total_t_loss = []\n",
    "    for step in range(401):\n",
    "        batch_index = (step*BATCH_SIZE)%(data_len+1-BATCH_SIZE)\n",
    "        batch_data = X_train[batch_index:batch_index+BATCH_SIZE]\n",
    "        batch_labels = y_train[batch_index:batch_index+BATCH_SIZE]\n",
    "\n",
    "        _, l = sess.run([optimizer, loss], feed_dict={x: batch_data, y: batch_labels})\n",
    "        total_t_loss.append(l)\n",
    "\n",
    "        if step%100 == 0:\n",
    "            avg_train_loss = np.mean(total_t_loss)\n",
    "            total_v_loss = []\n",
    "            for v_step in range(len(X_test)//BATCH_SIZE):\n",
    "                batch_index = (v_step*BATCH_SIZE)%(len(X_test)+1-BATCH_SIZE)\n",
    "\n",
    "                batch_data_v = X_test[batch_index:batch_index+BATCH_SIZE]\n",
    "                \n",
    "                batch_labels_v = y_test[batch_index:batch_index+BATCH_SIZE]\n",
    "\n",
    "                l_v = sess.run([loss], feed_dict={x: batch_data_v, y: batch_labels_v})\n",
    "            \n",
    "                total_v_loss.append(l_v[0])\n",
    "\n",
    "            print('{0} : {1}'.format(l, np.mean(total_v_loss)))\n",
    "            total_t_loss = []\n",
    "    # Build the submission file\n",
    "    X_eval, ids = process_data(test_path, True) \n",
    "\n",
    "    outputs = sess.run([logits], feed_dict={x: X_eval})\n",
    "    outputs = [x[1] for x in outputs[0]]\n",
    "\n",
    "    submission = ['ID,PredictedProb']\n",
    "\n",
    "    for prediction, id in zip(outputs, ids):\n",
    "        submission.append('{0},{1}'.format(id,prediction))\n",
    "\n",
    "    submission = '\\n'.join(submission)\n",
    "\n",
    "    with open('/Users/ngochuyenluu/Downloads/BNP/sample_submission.csv', 'w') as outfile:\n",
    "        outfile.write(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
